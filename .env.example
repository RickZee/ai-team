# ai-team environment template
# Copy to .env and adjust values.

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MEMORY_PRESET=default  # or 32gb for 7B/8B models (~8-10 GB peak)
# AI_TEAM_USE_REAL_LLM=0  # Set to 1 to run integration tests with real Ollama

# Per-role models (optional; fallback used if unset)
# MANAGER_MODEL=
# PRODUCT_OWNER_MODEL=
# ARCHITECT_MODEL=
# BACKEND_DEV_MODEL=
# FRONTEND_DEV_MODEL=
# DEVOPS_MODEL=
# CLOUD_MODEL=
# QA_MODEL=

# Guardrails
# GUARDRAIL_MAX_RETRIES=3
# CODE_QUALITY_MIN_SCORE=0.7
# TEST_COVERAGE_MIN=0.6
# MAX_FILE_SIZE_KB=500

# UI (Gradio)
# GRADIO_SERVER_PORT=7860
